# MCM 2023 Problem C - Wordle æ•°æ®åˆ†æžä¸Žé¢„æµ‹

> **2023 æ•°å­¦å»ºæ¨¡ç«žèµ› (MCM) Problem C: Predicting Wordle Results**
> 
> æœ¬é¡¹ç›®æä¾›å®Œæ•´çš„æ—¶é—´åºåˆ—é¢„æµ‹ã€å•è¯å±žæ€§åˆ†æžå’Œæˆç»©åˆ†å¸ƒé¢„æµ‹è§£å†³æ–¹æ¡ˆã€‚

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ðŸ“ é¡¹ç›®ç»“æž„ï¼ˆé‡æž„ç‰ˆ - 2025-12-16ï¼‰

```
MCM_2023_C/
â”œâ”€â”€ archives/                   # ç«žèµ›é¢˜ç›®å½’æ¡£
â”‚   â”œâ”€â”€ 2023_MCM_Problem_C.pdf
â”‚   â””â”€â”€ descriptive_stats_report.txt
â”œâ”€â”€ Q1/                         # Q1ï¼šæŠ¥å‘Šäººæ•°æ—¶é—´åºåˆ—é¢„æµ‹ä¸Žå¯¹æ¯”
â”‚   â”œâ”€â”€ q1_final_clean.py       # ä¸»ç¨‹åºï¼šå˜ç‚¹ + æ»šåŠ¨CV + SARIMAé›†æˆ + 90% CI
â”‚   â”œâ”€â”€ model_comparison.py     # ç»Ÿä¸€å£å¾„å¯¹æ¯”ï¼šEnsemble vs Prophet vs Chronos
â”‚   â”œâ”€â”€ viz_report.py           # è¯Šæ–­/æ•…äº‹åŒ–å›¾è¡¨ä¸ŽæŠ¥å‘Šç”Ÿæˆ
â”‚   â””â”€â”€ results/                # å·²ç”Ÿæˆçš„å›¾è¡¨/æŠ¥å‘Š/æ¨¡åž‹è¾“å‡º
â”‚       â”œâ”€â”€ *_weekday_effects.png, *_changepoint.png, *_diagnostics.png  # è¯Šæ–­å›¾
â”‚       â”œâ”€â”€ eda_*.png           # æŽ¢ç´¢æ€§æ•°æ®åˆ†æžå›¾ï¼ˆæ¦‚è§ˆ/å­£èŠ‚æ€§/æ³¢åŠ¨/åˆ†è§£ï¼‰
â”‚       â”œâ”€â”€ explanation_report.txt, diagnostic_report.txt...  # æ–‡æœ¬æŠ¥å‘Š
â”‚       â””â”€â”€ ensemble_result.pkl # æ¨¡åž‹ç»“æžœ
â”œâ”€â”€ å•è¯å±žæ€§/                   # Q2ï¼šå±žæ€§-è¡Œä¸º/éš¾åº¦åˆ†æžï¼ˆHard Mode / avg guessesï¼‰
â”‚   â”œâ”€â”€ enrich_features.py      # ä¸º data_with_features.xlsx å¢žåŠ è¯é¢‘/è¯æ€§ç­‰ç‰¹å¾å¹¶å¯¼å‡º data_final.csv
â”‚   â”œâ”€â”€ main.py                 # ä¸»å…¥å£ï¼šä¾æ¬¡è¿è¡Œ Hard Mode åˆ†æžã€éš¾åº¦é¢„æµ‹ã€çƒ­åŠ›å›¾ã€EERIEç¤ºä¾‹é¢„æµ‹
â”‚   â”œâ”€â”€ data_loader.py          # æ•°æ®æ¸…æ´—ã€åˆ†å¸ƒå½’ä¸€åŒ–ã€avg_guessesã€å…±çº¿æ€§è¿‡æ»¤ç­‰
â”‚   â”œâ”€â”€ analysis_hard_mode.py   # Hard Mode å æ¯”è§£é‡Šï¼ˆOLS/Lasso/Lagå¯¹æ¯”ï¼‰
â”‚   â”œâ”€â”€ analysis_difficulty.py  # éš¾åº¦å»ºæ¨¡ï¼ˆavg_guessesï¼Œå¤šæ¨¡åž‹ç«žæŠ€åœº + RFé‡è¦æ€§ + KMeansåˆ†çº§ï¼‰
â”‚   â”œâ”€â”€ analysis_heatmap.py     # RQ1/RQ2 ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆèŽ«å…°è¿ªé…è‰²ï¼‰
â”‚   â”œâ”€â”€ predict_eerie.py        # å¤šè¾“å‡ºRFï¼šé¢„æµ‹æŒ‡å®šå•è¯çš„åˆ†å¸ƒï¼ˆè‹¥ç¼ºè¯åˆ™æ¼”ç¤ºæµç¨‹ï¼‰
â”‚   â”œâ”€â”€ model_mmoe.py           # MMoE æ¨¡åž‹å®žçŽ°
â”‚   â”œâ”€â”€ style_utils.py          # å¯è§†åŒ–æ ·å¼å·¥å…·
â”‚   â”œâ”€â”€ data_with_features.xlsx # åŽŸå§‹ç‰¹å¾æ•°æ®
â”‚   â”œâ”€â”€ data_final.csv          # å¢žå¼ºåŽçš„æœ€ç»ˆæ•°æ®
â”‚   â”œâ”€â”€ analysis_report.txt     # åˆ†æžæŠ¥å‘Š
â”‚   â””â”€â”€ heatmap_*.png           # RQ1/RQ2 ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆå¤šç§é…è‰²ï¼‰
â”œâ”€â”€ forcasting/                 # Q3ï¼šåˆ†å¸ƒé¢„æµ‹æ¨¡åž‹ï¼ˆMoE + Softmaxï¼‰ä¸ŽåŸºçº¿
â”‚   â”œâ”€â”€ Moe_Softmax.py          # MoE åˆ†å¸ƒé¢„æµ‹ä¸»è„šæœ¬ï¼ˆè¯»å– data/mcm_processed_data.csvï¼‰
â”‚   â”œâ”€â”€ Moe_Softmax_with_probability.py  # å¸¦æ¦‚çŽ‡è¾“å‡ºçš„ MoE å˜ä½“
â”‚   â”œâ”€â”€ moe.py                  # MoE ç»“æž„ï¼ˆé—¨æŽ§ + å¤šä¸ªMLP+Softmaxä¸“å®¶ï¼‰
â”‚   â”œâ”€â”€ moe_tuning.py           # MoE è¶…å‚æœç´¢/å¯¹æ¯”
â”‚   â”œâ”€â”€ AutoEncoder.ipynb       # è‡ªç¼–ç å™¨å®žéªŒ
â”‚   â”œâ”€â”€ moe_output/             # MoE è®­ç»ƒäº§ç‰©
â”‚   â”‚   â”œâ”€â”€ moe_softmax_pred_output.csv  # é¢„æµ‹ç»“æžœ
â”‚   â”‚   â”œâ”€â”€ moe_report.json, moe_summary_report.txt  # æŠ¥å‘Š
â”‚   â”‚   â”œâ”€â”€ moe_training_history.png, moe_distribution_comparison.png  # è®­ç»ƒå›¾
â”‚   â”‚   â””â”€â”€ moe_expert_*.png    # ä¸“å®¶åˆ†æžå›¾
â”‚   â””â”€â”€ explore/                # é¢å¤–ï¼šç»Ÿä¸€å›žå½’/åˆ†å¸ƒåŸºçº¿æ¨¡åž‹åº“
â”‚       â”œâ”€â”€ run_all_models.py   # ç»Ÿä¸€è¿è¡Œæ‰€æœ‰æ¨¡åž‹
â”‚       â”œâ”€â”€ config.py           # é…ç½®æ–‡ä»¶
â”‚       â”œâ”€â”€ forecasting_models.py, distribution_models.py  # æ¨¡åž‹åº“
â”‚       â”œâ”€â”€ lasso_forcasting.py, ridge_forcasting.py...  # å„ç±»æ¨¡åž‹è„šæœ¬
â”‚       â””â”€â”€ *_results/          # å„æ¨¡åž‹ç»“æžœç›®å½•
â”œâ”€â”€ features/                   # ç‰¹å¾å·¥ç¨‹ä¸Žä»¿çœŸ/å¼ºåŒ–å­¦ä¹ ç”Ÿæˆè„šæœ¬
â”‚   â”œâ”€â”€ featureEngineering.ipynb  # ä¸»ç‰¹å¾å·¥ç¨‹ notebook
â”‚   â”œâ”€â”€ addOn.ipynb             # è¡¥å……ç‰¹å¾ notebook
â”‚   â”œâ”€â”€ wordle_game_simulate.py # Wordle ç­–ç•¥ä»¿çœŸ
â”‚   â”œâ”€â”€ reinforcement_learning_wordle_game.py  # A2C å¼ºåŒ–å­¦ä¹ 
â”‚   â””â”€â”€ feedbackEntropy.py      # åé¦ˆç†µè®¡ç®—
â”œâ”€â”€ data/                       # æ•°æ®ä¸Žä¸­é—´äº§ç‰©
â”‚   â”œâ”€â”€ mcm_processed_data.csv  # æ ¸å¿ƒç‰¹å¾æ•°æ®ï¼ˆ358æ¡æ ·æœ¬ï¼Œ55+ç‰¹å¾ï¼‰
â”‚   â”œâ”€â”€ reduced_features_train.csv, reduced_features_test.csv  # é™ç»´åŽç‰¹å¾
â”‚   â”œâ”€â”€ lasso_feature_importance.xlsx, lasso_reduced_features_importance.xlsx  # ç‰¹å¾é‡è¦æ€§
â”‚   â””â”€â”€ glove.6B/               # GloVe è¯å‘é‡ï¼ˆå¤§æ–‡ä»¶ï¼Œé»˜è®¤è¢« gitignoreï¼‰
â”œâ”€â”€ models/                     # è®­ç»ƒå¾—åˆ°çš„æ¨¡åž‹/é™ç»´å™¨
â”‚   â”œâ”€â”€ autoencoder_model.pkl   # è‡ªç¼–ç å™¨æ¨¡åž‹
â”‚   â”œâ”€â”€ autoencoder_wordle_tf.keras  # TensorFlow Keras æ¨¡åž‹
â”‚   â”œâ”€â”€ reduction_models/       # é™ç»´æ¨¡åž‹
â”‚   â””â”€â”€ wordle_a2c_ckpt/        # A2C å¼ºåŒ–å­¦ä¹ æ£€æŸ¥ç‚¹
â”œâ”€â”€ util/                       # å¯è§†åŒ–å·¥å…·
â”‚   â””â”€â”€ visualizations.py       # ç»Ÿä¸€å¯è§†åŒ–å‡½æ•°
â”œâ”€â”€ featureEngineering.ipynb    # æ ¹ç›®å½•ç‰¹å¾å·¥ç¨‹ notebookï¼ˆå¤‡ä»½ï¼‰
â”œâ”€â”€ AGENTS.md                   # é¡¹ç›®ä»£ç†è¯´æ˜Ž
â””â”€â”€ requirements.txt            # Python ä¾èµ–
```

---

## ðŸš€ å¿«é€Ÿå¼€å§‹

### çŽ¯å¢ƒè®¾ç½®

```bash
# åˆ›å»º conda çŽ¯å¢ƒï¼ˆæŽ¨è Python 3.11ï¼‰
conda create -n mcm2023 python=3.11 -y
conda activate mcm2023

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### ä¸€é”®è¿è¡Œ

```bash
# ä»»åŠ¡1ï¼šé¢„æµ‹ 2023-03-01 æŠ¥å‘Šäººæ•° + Hard Mode åˆ†æž
./run_task1.sh

# ä»»åŠ¡2ï¼šé¢„æµ‹ EERIE çš„æˆç»©åˆ†å¸ƒ
./run_task2.sh
```

**ä¸»è¦ä¾èµ–åº“ï¼š**
- `numpy`, `pandas`, `matplotlib`, `seaborn`, `scipy` (æ•°æ®å¤„ç†ä¸Žå¯è§†åŒ–)
- `statsmodels`, `scikit-learn` (ç»Ÿè®¡æ¨¡åž‹ä¸Žæœºå™¨å­¦ä¹ )
- `tensorflow` / `tensorflow-macos` (æ·±åº¦å­¦ä¹ /è‡ªç¼–ç å™¨ï¼ŒmacOS ä¸‹è‡ªåŠ¨é€‰æ‹©)
- `torch` (æ·±åº¦å­¦ä¹ /MoEæ¨¡åž‹)
- `ruptures`, `holidays` (å˜ç‚¹æ£€æµ‹ä¸ŽèŠ‚å‡æ—¥å¤„ç†)
- `nltk`, `wordfreq` (NLPç‰¹å¾æå–)

---

## ðŸŽ¯ é¢˜ç›®è¦æ±‚ä¸Žè§£å†³æ–¹æ¡ˆ

| é¢˜ç›®è¦æ±‚ | è§£å†³æ–¹æ¡ˆ | å®žçŽ°æ–‡ä»¶ |
|---------|---------|---------|
| **Q1a**: é¢„æµ‹ 2023-03-01 æŠ¥å‘Šäººæ•°ï¼ˆå«ç½®ä¿¡åŒºé—´ï¼‰ | SARIMA æ—¶é—´åºåˆ—é›†æˆ + å˜ç‚¹æ£€æµ‹ | `task1_reporting_volume/q1_final_clean.py` |
| **Q1b**: åˆ†æžå•è¯å±žæ€§å¯¹ Hard Mode çš„å½±å“ | OLS + Lasso + æ»žåŽç‰¹å¾åˆ†æž | `task1_reporting_volume/analysis_hard_mode.py` |
| **Q2**: é¢„æµ‹ EERIE çš„ 1-7 æ¬¡çŒœä¸­åˆ†å¸ƒ | Random Forestï¼ˆ79ç‰¹å¾ï¼‰ | `task2_distribution_prediction/predict_eerie.py` |

---

## ðŸ”¬ æ ¸å¿ƒæŠ€æœ¯æ–¹æ¡ˆ

### ðŸ“Š ä»»åŠ¡1ï¼šæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆæŠ¥å‘Šäººæ•°ï¼‰

**å…³é”®å‘çŽ°**ï¼š
- ðŸ”´ **å˜ç‚¹æ£€æµ‹**ï¼š2022-10-05 å‡ºçŽ°ç»“æž„æ€§æ–­è£‚ï¼ŒæŠ¥å‘Šäººæ•°ä»Ž 11.2ä¸‡/å¤© â†’ 2.6ä¸‡/å¤©ï¼ˆä¸‹é™ 77.1%ï¼‰
- ðŸ“ˆ **é¢„æµ‹ç»“æžœ**ï¼š2023-03-01 ç‚¹é¢„æµ‹ **20,181 äºº**ï¼Œ90% CI: [11,646, 34,971]
- ðŸ“Š **æ¨¡åž‹æ€§èƒ½**ï¼š
  - CVè¦†ç›–çŽ‡: 97.8% (ç†æƒ³: 95%)
  - Walk-Forward h=60å¤©è¦†ç›–çŽ‡: **97.9%** (ç›®æ ‡: ~90%)
  - Walk-Forward h=30å¤©è¦†ç›–çŽ‡: **96.7%**

**æŠ€æœ¯æ ˆ**ï¼š
```python
âœ“ å˜ç‚¹æ£€æµ‹ (PELT)          # åœ¨logç©ºé—´æ£€æµ‹è¶‹åŠ¿çªå˜
âœ“ SARIMA(1,1,2)x(1,0,1,7)  # æ•æ‰å‘¨å‘¨æœŸæ€§ï¼ˆ7å¤©ï¼‰
âœ“ æ»šåŠ¨äº¤å‰éªŒè¯              # é¿å…æ•°æ®æ³„éœ²
âœ“ é›†æˆå­¦ä¹  (IVW)           # é€†æ–¹å·®åŠ æƒ
âœ“ å…¨æ¦‚çŽ‡æ–¹å·®å…¬å¼            # Law of Total Varianceï¼ˆé¢„æµ‹åŒºé—´ï¼‰
âœ“ Duan Smearing            # å¯¹æ•°å›žå˜æ¢ä¿®æ­£
âœ“ å•è¯å±žæ€§ç‰¹å¾              # lag0 + lag1 å…±10ä¸ªç‰¹å¾
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `results/task1/explanation_report.txt` - è§£é‡Šæ€§æŠ¥å‘Š
- `results/task1/diagnostic_report.txt` - æ¨¡åž‹è¯Šæ–­
- `pictures/task1/1_weekday_effects.png` - å·¥ä½œæ—¥æ•ˆåº”
- `pictures/task1/2_changepoint.png` - å˜ç‚¹å¯è§†åŒ–
- `pictures/task1/3_diagnostics.png` - æ®‹å·®è¯Šæ–­

### ðŸŽ¯ ä»»åŠ¡1ï¼ˆæ”¹è¿›ç‰ˆï¼‰ï¼šæ—¶é—´åºåˆ—é¢„æµ‹ + å•è¯å±žæ€§ç‰¹å¾

**æ ¸å¿ƒæ”¹è¿›**ï¼ˆ2025-12-17 æœ€æ–°ï¼‰ï¼š
- ðŸ†• **æ·»åŠ å½“å¤©å•è¯å±žæ€§**ï¼ˆlag0_*ï¼‰ï¼š5ä¸ªç‰¹å¾
  - `lag0_mean_simulate_freq` - å½“å¤©å•è¯æ¨¡æ‹Ÿå¹³å‡å°è¯•æ¬¡æ•°
  - `lag0_letter_entropy` - å½“å¤©å•è¯å­—æ¯ç†µ
  - `lag0_mean_simulate_random` - å½“å¤©å•è¯éšæœºç­–ç•¥å°è¯•æ¬¡æ•°
  - `lag0_has_common_suffix` - å½“å¤©å•è¯æ˜¯å¦æœ‰å¸¸è§åŽç¼€
  - `lag0_letter_freq_mean` - å½“å¤©å•è¯å­—æ¯å¹³å‡é¢‘çŽ‡
  
- ðŸ†• **æ·»åŠ å‰ä¸€å¤©å•è¯å±žæ€§**ï¼ˆlag1_*ï¼‰ï¼š5ä¸ªç‰¹å¾
  - `lag1_mean_simulate_freq` - å‰ä¸€å¤©å•è¯æ¨¡æ‹Ÿå¹³å‡å°è¯•æ¬¡æ•°
  - `lag1_letter_entropy` - å‰ä¸€å¤©å•è¯å­—æ¯ç†µ
  - `lag1_mean_simulate_random` - å‰ä¸€å¤©å•è¯éšæœºç­–ç•¥å°è¯•æ¬¡æ•°
  - `lag1_has_common_suffix` - å‰ä¸€å¤©å•è¯æ˜¯å¦æœ‰å¸¸è§åŽç¼€
  - `lag1_letter_freq_mean` - å‰ä¸€å¤©å•è¯å­—æ¯å¹³å‡é¢‘çŽ‡
  
- ðŸ”§ **ç‰¹å¾é›†æ‰©å±•**ï¼šåŽŸ 3 ä¸ª â†’ çŽ° 13 ä¸ª
  - åŸºç¡€ç‰¹å¾: `regime`, `is_weekend`, `is_holiday`
  - å½“å¤©å•è¯: 5ä¸ª lag0_* ç‰¹å¾ï¼ˆè´¡çŒ® 31.2%ï¼‰
  - å‰ä¸€å¤©å•è¯: 5ä¸ª lag1_* ç‰¹å¾ï¼ˆè´¡çŒ® 22.7%ï¼‰

- ðŸ› **å…³é”®Bugä¿®å¤**ï¼š
  - âœ… ä¿®å¤ regime ç‰¹å¾åœ¨æµ‹è¯•é›†ä¸­çš„è®¾ç½®é€»è¾‘ï¼ˆåŸºäºŽç»å¯¹ä½ç½®ï¼‰
  - âœ… ä¿®å¤ ensemble æ–¹å·®åˆå¹¶å…¬å¼ï¼ˆä»Žä¼°è®¡é‡æ–¹å·®â†’é¢„æµ‹æ–¹å·®ï¼‰
  - âœ… ä½¿ç”¨å…¨æ¦‚çŽ‡å…¬å¼: `Var(Y) = E[Var(Y|Model)] + Var[E(Y|Model)]`
  - âœ… Walk-Forward è¦†ç›–çŽ‡ä»Ž **68.3% â†’ 97.9%** â­

**Hard Mode å½±å“å› ç´ **ï¼š
- ðŸ“Œ **æ»žåŽæ•ˆåº”å ä¸»å¯¼**ï¼šå‰2-3å¤©çš„ Hard Mode æ¯”ä¾‹è´¡çŒ® **98%+ é‡è¦æ€§**
- ðŸ”¤ **å•è¯å±žæ€§å½±å“å¾®å¼±**ï¼šOLS RÂ² = 0.23ï¼ŒLasso ä»…ä¿ç•™ 20/79 ç‰¹å¾

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `pictures/task1/Feature_Importance_Hard_Mode_Ratio_Lag_vs_Attributes.png`

### ðŸŽ² ä»»åŠ¡2ï¼šæˆç»©åˆ†å¸ƒé¢„æµ‹ï¼ˆEERIEï¼‰

**é¡¹ç›®ç»“æž„è°ƒæ•´**ï¼š
- ðŸ”¬ **`feature_engineering/`**ï¼šç‹¬ç«‹çš„ç‰¹å¾å·¥ç¨‹æ¨¡å—ï¼ˆåŒ…å« AutoEncoder é™ç»´ï¼‰
- ðŸ“‚ **`experiments/`**ï¼šæŽ¢ç´¢æ€§åˆ†æžï¼ˆLasso, XGBoost, MLP ç­‰å®žéªŒï¼‰
- â­ **`models/`**ï¼šå®žé™…è§£å†³æ–¹æ¡ˆï¼ˆRandom Forest è®­ç»ƒè„šæœ¬ï¼‰

**æ•°æ®é©±åŠ¨**ï¼š
- ðŸ“Š **è®­ç»ƒæ•°æ®**ï¼š358 ä¸ªå•è¯ Ã— 79 ä¸ªç‰¹å¾ï¼ˆæ¥è‡ª `feature_engineering/`ï¼‰
- ðŸŽ¯ **é¢„æµ‹ç›®æ ‡**ï¼š7 ä¸ªç±»åˆ«ï¼ˆ1-6 tries + 7+ triesï¼‰

**ç‰¹å¾å·¥ç¨‹**ï¼ˆ79 ç»´ï¼‰ï¼š
```
å­—æ¯ç»“æž„: num_rare_letters, has_double_letter, max_consecutive_vowels...
è¯é¢‘: Zipf-value, letter_freq_mean, positional_freq_mean...
ç†µ: letter_entropy, feedback_entropy, position_self_entropy...
è¯­ä¹‰: semantic_distance, semantic_neighbors_count...
æ¨¡æ‹Ÿ: *_simulate_random, *_simulate_freq (æ¥è‡ª wordle_game_simulate.py)
å¼ºåŒ–å­¦ä¹ : rl_*_try_* (æ¥è‡ª reinforcement_learning_wordle_game.py)
é™ç»´: autoencoder_value (æ¥è‡ª AutoEncoder.ipynb)
```

**æ¨¡åž‹é€‰æ‹©**ï¼šRandom Forestï¼ˆåŸºäºŽå®žéªŒå¯¹æ¯”é€‰å‡ºï¼‰

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `results/task2/eerie_prediction.csv` - EERIE é¢„æµ‹ç»“æžœ
- `pictures/task2/eerie_distribution.png` - åˆ†å¸ƒå¯¹æ¯”å›¾

---

## ðŸ“Š æ•°æ®è¯´æ˜Ž

### â­ æ ¸å¿ƒæ•°æ®ï¼š`data/mcm_processed_data.csv`

| ç±»åž‹ | åˆ—æ•° | è¯´æ˜Ž |
|-----|-----|------|
| åŸºç¡€ä¿¡æ¯ | 3 | `date`, `word`, `contest_number` |
| æŠ¥å‘Šäººæ•° | 2 | `number_of_reported_results`, `number_in_hard_mode` |
| çœŸå®žåˆ†å¸ƒ | 7 | `1_try` ~ `7_or_more_tries_x` |
| å•è¯ç‰¹å¾ | 79 | å­—æ¯ç»“æž„ã€è¯é¢‘ã€ç†µã€è¯­ä¹‰ã€ä»¿çœŸã€RL... |

**âš ï¸ é‡è¦**ï¼š
- âœ… **CSV æ–‡ä»¶**åŒ…å«çœŸå®žæŠ¥å‘Šäººæ•°ï¼ˆå‡ ä¸‡äººè§„æ¨¡ï¼‰
- âŒ **Excel æ–‡ä»¶**ï¼ˆ`backups/2023_MCM_Problem_C_Data.xlsx`ï¼‰æ˜¯å½’ä¸€åŒ–çš„ç™¾åˆ†æ¯”æ•°æ®ï¼ˆ0-100ï¼‰

---

## ðŸ› ï¸ æŠ€æœ¯æ ˆ

### æ ¸å¿ƒä¾èµ–

```python
pandas>=2.0.0         # æ•°æ®å¤„ç†
numpy>=1.24.0         # æ•°å€¼è®¡ç®—
matplotlib>=3.7.0     # ç»˜å›¾
seaborn>=0.12.0       # ç»Ÿè®¡å¯è§†åŒ–
scikit-learn>=1.3.0   # æœºå™¨å­¦ä¹ 
statsmodels>=0.14.0   # ç»Ÿè®¡æ¨¡åž‹ï¼ˆSARIMAï¼‰
ruptures>=1.1.0       # å˜ç‚¹æ£€æµ‹
holidays>=0.34        # èŠ‚å‡æ—¥æ•°æ®
wordfreq>=3.0         # è¯é¢‘ç»Ÿè®¡
nltk>=3.8             # NLP å·¥å…·
```

### å¯é€‰ä¾èµ–

```python
torch>=2.0.0          # æ·±åº¦å­¦ä¹ ï¼ˆç”¨äºŽ MoE å®žéªŒï¼‰
xgboost>=2.0.0        # æ¢¯åº¦æå‡ï¼ˆç”¨äºŽå¯¹æ¯”å®žéªŒï¼‰
```

---

## ðŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜Ž

### ä»»åŠ¡1ï¼šæŠ¥å‘Šäººæ•°é¢„æµ‹

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ shell è„šæœ¬ï¼ˆæŽ¨èï¼‰
./run_task1.sh

# æ–¹æ³•2ï¼šç›´æŽ¥è¿è¡Œ Python
cd task1_reporting_volume
conda run -n mcm2023 python run_task1.py
```

è¾“å‡ºä½äºŽ `forcasting/moe_output/`ï¼š
- **[é¢„æµ‹ç»“æžœ]** `moe_softmax_pred_output.csv`, `moe_expert_distribution_summary_test.csv`
- **[æŠ¥å‘Š]** `moe_report.json`, `moe_summary_report.txt`
- **[å¯è§†åŒ–]** `moe_training_history.png`, `moe_distribution_comparison.png`, `moe_error_analysis.png`
- **[ä¸“å®¶åˆ†æž]** `moe_expert_usage.png`, `moe_expert_mean_distribution_test.png`, `moe_expert_sample_ratio_test.png`
- **[ç»¼åˆæŠ¥å‘Š]** `moe_comprehensive_summary.png`, `moe_performance_metrics.png`, `moe_aux_loss.png`

3. **æ¨¡åž‹æ–‡ä»¶**ï¼ˆ`results/task1/`ï¼‰ï¼š
   - `ensemble_result.pkl` - é›†æˆæ¨¡åž‹ï¼ˆå¯ç”¨äºŽåŽç»­é¢„æµ‹ï¼‰

### ä»»åŠ¡2ï¼šEERIE åˆ†å¸ƒé¢„æµ‹

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ shell è„šæœ¬ï¼ˆæŽ¨èï¼‰
./run_task2.sh

# æ–¹æ³•2ï¼šç›´æŽ¥è¿è¡Œ Python
cd task2_distribution_prediction
conda run -n mcm2023 python predict_eerie.py
```

**è¾“å‡ºè¯¦æƒ…**ï¼š
1. **é¢„æµ‹ç»“æžœ**ï¼ˆ`results/task2/`ï¼‰ï¼š
   - `eerie_prediction.csv` - EERIE çš„ 1-7 æ¬¡åˆ†å¸ƒæ¦‚çŽ‡
   
2. **å¯è§†åŒ–å›¾è¡¨**ï¼ˆ`pictures/task2/`ï¼‰ï¼š
   - `eerie_distribution.png` - é¢„æµ‹åˆ†å¸ƒ vs å¹³å‡åˆ†å¸ƒå¯¹æ¯”

---

## ðŸ” é¡¹ç›®äº®ç‚¹

### âœ¨ æ–¹æ³•åˆ›æ–°

1. **å˜ç‚¹æ£€æµ‹ + åˆ†æ®µå»ºæ¨¡**
   - ä½¿ç”¨ PELT ç®—æ³•è‡ªåŠ¨æ£€æµ‹æ—¶é—´åºåˆ—çš„ç»“æž„æ€§å˜åŒ–
   - é¿å…æ•°æ®æ³„éœ²ï¼šæ»šåŠ¨ CV ä¸­æ¯ä¸€æŠ˜ç‹¬ç«‹æ£€æµ‹å˜ç‚¹

2. **é›†æˆå­¦ä¹ ç­–ç•¥**
   - å¤šä¸ª SARIMA æ¨¡åž‹é€šè¿‡é€†æ–¹å·®åŠ æƒé›†æˆ
   - åœ¨ log ç©ºé—´åˆå¹¶é¢„æµ‹åŒºé—´ï¼Œæé«˜è¦†ç›–çŽ‡å‡†ç¡®æ€§

3. **æƒ¯æ€§æ•ˆåº”å‘çŽ°**
   - Hard Mode ä½¿ç”¨å…·æœ‰å¼ºæ—¶é—´æƒ¯æ€§ï¼ˆæ»žåŽæ•ˆåº”å  98%+ï¼‰
   - å•è¯å±žæ€§å¯¹å½“å¤© Hard Mode æ¯”ä¾‹å½±å“å¾®å¼±

### ðŸ“Š æ•°æ®å·¥ç¨‹

1. **ç‰¹å¾å·¥ç¨‹å®Œå–„**
   - 79 ç»´å•è¯ç‰¹å¾æ¶µç›–å­—æ¯ã€è¯é¢‘ã€ç†µã€è¯­ä¹‰ã€ä»¿çœŸã€RL
   - è‡ªåŠ¨åŒ–ç‰¹å¾è®¡ç®—æµç¨‹

2. **æ•°æ®è´¨é‡ä¿éšœ**
   - è¯†åˆ«å¹¶ä¿®å¤ Excel å½’ä¸€åŒ–æ•°æ®é—®é¢˜
   - ä½¿ç”¨ CSV çœŸå®žæ•°æ®è¿›è¡Œå»ºæ¨¡

### ðŸŽ¯ å¯è§£é‡Šæ€§

1. **è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ**
   - å˜ç‚¹ä½ç½®ã€åŽŸå› åˆ†æž
   - å‘¨æœ«æ•ˆåº”ã€èŠ‚å‡æ—¥æ•ˆåº”é‡åŒ–
   - æ¨¡åž‹æ€§èƒ½è¯Šæ–­ï¼ˆæ®‹å·®ã€è¦†ç›–çŽ‡ï¼‰

2. **å¯è§†åŒ–å®Œæ•´**
   - æ¯ä¸ªåˆ†æžæ­¥éª¤éƒ½æœ‰å¯¹åº”å›¾è¡¨
   - å›¾è¡¨é£Žæ ¼ç»Ÿä¸€ï¼Œä¿¡æ¯æ¸…æ™°

---

## ðŸ“ é‡è¦è¯´æ˜Ž

### âš ï¸ æ•°æ®æ ¼å¼è­¦å‘Š

- **Excel æ–‡ä»¶**ï¼ˆ`backups/2023_MCM_Problem_C_Data.xlsx`ï¼‰ï¼š
  - åŒ…å«çš„æ˜¯**å½’ä¸€åŒ–çš„ç™¾åˆ†æ¯”æ•°æ®**ï¼ˆ0-100ï¼‰
  - **ä¸æ˜¯**çœŸå®žçš„æŠ¥å‘Šäººæ•°
  - ä¸»è¦ç”¨äºŽç‰¹å¾åˆ—çš„èŽ·å–

- **CSV æ–‡ä»¶**ï¼ˆ`data/mcm_processed_data.csv`ï¼‰ï¼š
  - åŒ…å«**çœŸå®žçš„æŠ¥å‘Šäººæ•°**ï¼ˆå‡ ä¸‡äººè§„æ¨¡ï¼‰
  - åŒ…å«å®Œæ•´çš„ 79 ç»´å•è¯ç‰¹å¾
  - **æ‰€æœ‰å»ºæ¨¡éƒ½åŸºäºŽæ­¤æ–‡ä»¶**

### ðŸ“‚ æ–‡ä»¶ç»„ç»‡

- **ç»“æžœæ–‡ä»¶**ç»Ÿä¸€å­˜æ”¾åœ¨ `results/task1/` å’Œ `results/task2/`
- **å›¾è¡¨æ–‡ä»¶**ç»Ÿä¸€å­˜æ”¾åœ¨ `pictures/task1/` å’Œ `pictures/task2/`
- **ä¸å†æœ‰**å­æ–‡ä»¶å¤¹ä¸‹çš„é‡å¤ `results/` ç›®å½•

---

## ðŸ¤ è´¡çŒ®

æ¬¢è¿Žæäº¤ Issue å’Œ Pull Requestï¼

---

## ðŸ“„ License

MIT License

---

## ðŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ GitHub Issues è”ç³»ã€‚

---

**æœ€åŽæ›´æ–°**: 2025-12-17  
**é¡¹ç›®çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

---
*Created for 2023 MCM Problem C Solution.*

# é™„å½•

```mermaid
graph LR
    %% å®šä¹‰æ ·å¼
    classDef input fill:#E3F2FD,stroke:#1565C0,stroke-width:2px;
    classDef layer fill:#FFECB3,stroke:#FF6F00,stroke-width:2px,rounded;
    classDef gateBlock fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px;
    classDef expertBlock fill:#F8BBD0,stroke:#C2185B,stroke-width:2px;
    classDef operation fill:#E1BEE7,stroke:#6A1B9A,stroke-width:1px,stroke-dasharray: 5 5;
    classDef output fill:#FFF9C4,stroke:#FBC02D,stroke-width:2px;
    classDef loss fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px;

    %% è¾“å…¥å±‚
    Input[è¾“å…¥ç‰¹å¾ Input Tensor]:::input -->|"å½¢çŠ¶: (Batch, 55)"| SplitPoint((åˆ†æµç‚¹));

    %% åˆ†æµ
    SplitPoint --> GatingNetwork;
    SplitPoint --> Dispatcher;

    %% --- é—¨æŽ§ç½‘ç»œ (Gating Network) ---
    subgraph Gating_Mechanism ["é—¨æŽ§æœºåˆ¶ (Noisy Top-K Gating)"]
        direction TB
        GatingNetwork["é—¨æŽ§çº¿æ€§å±‚ (Linear)"]:::gateBlock;
        Noise["æ·»åŠ å™ªå£° (è®­ç»ƒæ—¶)"]:::operation;
        SoftmaxGate["Softmax Activation"]:::gateBlock;
        TopK["Top-K Selection (k=1) & Normalize"]:::gateBlock;

        GatingNetwork --"Logits (Batch, 2)"--> Noise --> SoftmaxGate --> TopK;
        
        %% è¾…åŠ©æŸå¤±è·¯å¾„
        TopK -.->|"ä¸“å®¶è´Ÿè½½ç»Ÿè®¡"| AuxLoss["è¾…åŠ©æŸå¤± (è´Ÿè½½å‡è¡¡)"]:::loss;
    end

    TopK --"ç¨€ç–é—¨æŽ§æƒé‡ Gates\n(Batch, 2, ä»…1ä¸ªéžé›¶)"--> Dispatcher;
    TopK --"é—¨æŽ§æƒé‡ç”¨äºŽåŠ æƒ"--> Combiner;

    %% --- è·¯ç”±ä¸Žä¸“å®¶å±‚ ---
    Dispatcher["ç¨€ç–è°ƒåº¦å™¨ (Sparse Dispatcher)\næ ¹æ®Gatesè·¯ç”±æ ·æœ¬"]:::operation;

    subgraph Mixture_of_Experts ["æ··åˆä¸“å®¶å±‚ (Mixture of Experts)"]
        direction TB
        
        %% ä¸“å®¶ 1
        subgraph Expert_0 ["ä¸“å®¶ 0 (MLP)"]
            direction LR
            E0_L1["Linear (55â†’64)"]:::layer --> E0_ReLU["ReLU"]:::layer --> E0_L2["Linear (64â†’7)"]:::layer --> E0_Softmax["Softmax"]:::layer;
        end
        
        %% ä¸“å®¶ 2
        subgraph Expert_1 ["ä¸“å®¶ 1 (MLP)"]
            direction LR
            E1_L1["Linear (55â†’64)"]:::layer --> E1_ReLU["ReLU"]:::layer --> E1_L2["Linear (64â†’7)"]:::layer --> E1_Softmax["Softmax"]:::layer;
        end
    end

    %% è·¯ç”±è¿žæŽ¥
    Dispatcher --"è·¯ç”±æ ·æœ¬å­é›† 0"--> E0_L1;
    Dispatcher --"è·¯ç”±æ ·æœ¬å­é›† 1"--> E1_L1;

    %% ä¸“å®¶è¾“å‡º
    E0_Softmax --"ä¸“å®¶0è¾“å‡º (Sub-Batch, 7)"--> Combiner;
    E1_Softmax --"ä¸“å®¶1è¾“å‡º (Sub-Batch, 7)"--> Combiner;

    %% --- èšåˆä¸Žè¾“å‡º ---
    Combiner["åŠ æƒç»„åˆ (Weighted Combination)\nâˆ‘ (Gate_i * Expert_i_Output)"]:::operation;
    
    Combiner --> FinalOutput["æœ€ç»ˆé¢„æµ‹è¾“å‡º\n(æ¦‚çŽ‡åˆ†å¸ƒ)"]:::output;

    %% æœ€ç»ˆè¾“å‡ºæ ‡æ³¨
    FinalOutput --"å½¢çŠ¶: (Batch, 7)\nSum=1"--> End((ç»“æŸ));
    AuxLoss -.->|"åŠ å…¥æ€»æŸå¤±"| End;

    %% æ³¨é‡Š
    note[/"æ³¨ï¼šç”±äºŽ k=1ï¼Œå¯¹äºŽæ¯ä¸ªæ ·æœ¬ï¼Œ\né—¨æŽ§å®žé™…ä¸Šæ˜¯é€‰æ‹©ä¸€ä¸ªä¸“å®¶ï¼Œ\nç»„åˆé˜¶æ®µé€šè¿‡é—¨æŽ§æƒé‡(æŽ¥è¿‘1)ä¼ é€’è¯¥ä¸“å®¶çš„è¾“å‡ºã€‚"/]:::operation
    TopK -.-> note
```
