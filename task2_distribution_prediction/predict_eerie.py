"""
ä»»åŠ¡2ï¼šé¢„æµ‹ EERIE åœ¨ 2023-03-01 çš„æˆç»©åˆ†å¸ƒ

åŠŸèƒ½ï¼š
1. è®¡ç®— EERIE çš„æ‰€æœ‰ç‰¹å¾
2. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ
3. é‡åŒ–ä¸ç¡®å®šæ€§
4. ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼ˆCSV + TXT + å¯è§†åŒ–ï¼‰

è¾“å‡ºï¼š
- results/task2/eerie_distribution.csv     (7ä¸ªç™¾åˆ†æ¯”)
- results/task2/eerie_full_report.txt      (å®Œæ•´æŠ¥å‘Šå«ä¸ç¡®å®šæ€§)
- results/task2/eerie_visualization.png    (å¯è§†åŒ–å›¾è¡¨)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
import os
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

# å¯¼å…¥é¡¹ç›®é…ç½®
from shared import PROCESSED_DATA, TASK2_RESULTS, TASK2_PICTURES, MODELS_DIR

print("\n" + "="*70)
print("ä»»åŠ¡2ï¼šé¢„æµ‹ EERIE çš„æˆç»©åˆ†å¸ƒ")
print("="*70 + "\n")


# ============ æ­¥éª¤1ï¼šè®¡ç®— EERIE ç‰¹å¾ ============
print("[æ­¥éª¤ 1/5] è®¡ç®— EERIE çš„ç‰¹å¾...")

from compute_eerie_features import compute_eerie_features

word = "EERIE"
date = "2023-03-01"

# è®¡ç®— EERIE çš„å®Œæ•´ç‰¹å¾
eerie_features_full = compute_eerie_features()
print(f"  âœ“ è®¡ç®—äº† {len(eerie_features_full.columns)} ä¸ªç‰¹å¾")


# ============ æ­¥éª¤2ï¼šåŠ è½½è®­ç»ƒæ•°æ®å’Œæ¨¡å‹ ============
print("\n[æ­¥éª¤ 2/5] åŠ è½½è®­ç»ƒæ•°æ®...")

df = pd.read_csv(PROCESSED_DATA)
print(f"  âœ“ åŠ è½½äº† {len(df)} å¤©çš„æ•°æ®")
print(f"  âœ“ æ•°æ®è·¯å¾„: {PROCESSED_DATA}")

# ç›®æ ‡å˜é‡
dist_cols = ['1_try', '2_tries', '3_tries', '4_tries', '5_tries', '6_tries', '7_or_more_tries_x']

# ç‰¹å¾åˆ—ï¼ˆæ’é™¤éç‰¹å¾åˆ—ï¼‰
exclude_cols = ['date', 'contest_number', 'word', 'number_of_reported_results',
                'number_in_hard_mode', 'sum'] + dist_cols
feature_cols = [col for col in df.columns if col not in exclude_cols]

X = df[feature_cols].fillna(df[feature_cols].mean())
y = df[dist_cols].fillna(0)

print(f"  âœ“ ç‰¹å¾æ•°: {len(feature_cols)}, æ ·æœ¬æ•°: {len(X)}")


# ============ æ­¥éª¤3ï¼šè®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœæ²¡æœ‰ä¿å­˜çš„æ¨¡å‹ï¼‰============
print("\n[æ­¥éª¤ 3/5] è®­ç»ƒ/åŠ è½½é¢„æµ‹æ¨¡å‹...")

model_file = '../models/distribution_rf_model.pkl'

if os.path.exists(model_file):
    import pickle
    with open(model_file, 'rb') as f:
        model = pickle.load(f)
    print(f"  âœ“ åŠ è½½å·²æœ‰æ¨¡å‹: {model_file}")
else:
    from sklearn.ensemble import RandomForestRegressor
    print("  è®­ç»ƒæ–°æ¨¡å‹...")
    model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
    model.fit(X, y)
    
    # ä¿å­˜æ¨¡å‹
    os.makedirs('../models', exist_ok=True)
    import pickle
    with open(model_file, 'wb') as f:
        pickle.dump(model, f)
    print(f"  âœ“ æ¨¡å‹å·²ä¿å­˜: {model_file}")


# ============ æ­¥éª¤4ï¼šé¢„æµ‹ EERIE ============
print("\n[æ­¥éª¤ 4/5] é¢„æµ‹ EERIE çš„åˆ†å¸ƒ...")

# å¯¹é½ EERIE ç‰¹å¾ä¸è®­ç»ƒæ•°æ®ç‰¹å¾
print("  å¯¹é½ç‰¹å¾åˆ—...")
for col in feature_cols:
    if col not in eerie_features_full.columns:
        # ç¼ºå¤±ç‰¹å¾ç”¨è®­ç»ƒæ•°æ®å‡å€¼å¡«å……
        eerie_features_full[col] = X[col].mean()

# æŒ‰ç…§è®­ç»ƒç‰¹å¾é¡ºåºé‡æ’
X_eerie = eerie_features_full[feature_cols]
print(f"  âœ“ ç‰¹å¾å¯¹é½å®Œæˆï¼Œå…± {len(feature_cols)} ä¸ªç‰¹å¾")

# ä½¿ç”¨éšæœºæ£®æ—çš„æ¯æ£µæ ‘è¿›è¡Œé¢„æµ‹ï¼ˆä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
tree_predictions = []
for tree in model.estimators_:
    pred = tree.predict(X_eerie)
    tree_predictions.append(pred[0])

tree_predictions = np.array(tree_predictions)
mean_pred = tree_predictions.mean(axis=0)
std_pred = tree_predictions.std(axis=0)

# å½’ä¸€åŒ–åˆ° 100%
mean_pred = mean_pred / mean_pred.sum()

print(f"  âœ“ ä½¿ç”¨äº† {len(model.estimators_)} æ£µå†³ç­–æ ‘")
print(f"  âœ“ é¢„æµ‹å®Œæˆ")


# ============ æ­¥éª¤5ï¼šç”Ÿæˆè¾“å‡º ============
print("\n[æ­¥éª¤ 5/5] ç”Ÿæˆç»“æœ...")
print(f"  âœ“ ç»“æœç›®å½•: {TASK2_RESULTS}")
print(f"  âœ“ å›¾ç‰‡ç›®å½•: {TASK2_PICTURES}")

# 5.1 ä¿å­˜ CSVï¼ˆç®€æ´ç‰ˆï¼‰
categories = ['1_try', '2_tries', '3_tries', '4_tries', '5_tries', '6_tries', '7_or_more_tries']
results_df = pd.DataFrame({
    'category': categories,
    'percentage': mean_pred * 100,
    'std': std_pred * 100
})
csv_file = TASK2_RESULTS / 'eerie_distribution.csv'
results_df.to_csv(csv_file, index=False)
print(f"  âœ“ CSV å·²ä¿å­˜: {csv_file}")

# 5.2 ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
report_file = TASK2_RESULTS / 'eerie_full_report.txt'
with open(report_file, 'w') as f:
    f.write("="*70 + "\n")
    f.write(f"Wordle é¢„æµ‹æŠ¥å‘Š: {word} ({date})\n")
    f.write("="*70 + "\n\n")
    
    f.write("é¢„æµ‹åˆ†å¸ƒ:\n")
    f.write("-"*70 + "\n")
    f.write(f"{'ç±»åˆ«':15s} | {'ç™¾åˆ†æ¯”':10s} | {'95% ç½®ä¿¡åŒºé—´':20s}\n")
    f.write("-"*70 + "\n")
    
    for i, cat in enumerate(categories):
        pct = mean_pred[i] * 100
        std = std_pred[i] * 100
        lower = max(0, pct - 1.96 * std)
        upper = min(100, pct + 1.96 * std)
        f.write(f"{cat:15s} | {pct:9.2f}% | [{lower:6.2f}%, {upper:6.2f}%]\n")
    
    f.write("-"*70 + "\n")
    f.write(f"æ€»è®¡: {mean_pred.sum()*100:.1f}%\n")
    f.write("-"*70 + "\n\n")
    
    # ä¸ç¡®å®šæ€§æŒ‡æ ‡
    f.write("ä¸ç¡®å®šæ€§æŒ‡æ ‡:\n")
    f.write(f"  å¹³å‡æ ‡å‡†å·®: {std_pred.mean()*100:.2f}%\n")
    max_std_idx = np.argmax(std_pred)
    f.write(f"  æœ€ä¸ç¡®å®šç±»åˆ«: {categories[max_std_idx]} (std={std_pred[max_std_idx]*100:.2f}%)\n")
    
    # ç†µ
    epsilon = 1e-10
    entropy = -np.sum(mean_pred * np.log(mean_pred + epsilon))
    f.write(f"  é¢„æµ‹ç†µ: {entropy:.3f}\n\n")
    
    # æœŸæœ›å°è¯•æ¬¡æ•°
    attempt_numbers = np.array([1, 2, 3, 4, 5, 6, 9])
    expected_attempts = np.sum(mean_pred * attempt_numbers)
    f.write(f"æœŸæœ›å°è¯•æ¬¡æ•°: {expected_attempts:.2f}\n")
    f.write(f"æˆåŠŸç‡: {mean_pred[:6].sum()*100:.1f}%\n")
    f.write(f"å¤±è´¥ç‡: {mean_pred[6]*100:.1f}%\n")
    
    f.write("\n" + "="*70 + "\n")

print(f"  âœ“ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

# 5.3 å¯è§†åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# å·¦å›¾ï¼šåˆ†å¸ƒæŸ±çŠ¶å›¾
x = np.arange(len(categories))
ax1.bar(x, mean_pred * 100, yerr=std_pred * 1.96 * 100, 
        alpha=0.7, capsize=5, color='steelblue')
ax1.set_xlabel('å°è¯•æ¬¡æ•°')
ax1.set_ylabel('ç™¾åˆ†æ¯” (%)')
ax1.set_title(f'{word} é¢„æµ‹åˆ†å¸ƒ ({date})')
ax1.set_xticks(x)
ax1.set_xticklabels(['1', '2', '3', '4', '5', '6', '7+'])
ax1.grid(axis='y', alpha=0.3)

# å³å›¾ï¼šç´¯ç§¯åˆ†å¸ƒ
cumulative = np.cumsum(mean_pred) * 100
ax2.plot(x, cumulative, marker='o', linewidth=2, markersize=8, color='darkred')
ax2.fill_between(x, 0, cumulative, alpha=0.3, color='red')
ax2.set_xlabel('å°è¯•æ¬¡æ•°')
ax2.set_ylabel('ç´¯ç§¯ç™¾åˆ†æ¯” (%)')
ax2.set_title(f'{word} ç´¯ç§¯åˆ†å¸ƒ')
ax2.set_xticks(x)
ax2.set_xticklabels(['1', '2', '3', '4', '5', '6', '7+'])
ax2.grid(True, alpha=0.3)
ax2.set_ylim([0, 105])

plt.tight_layout()
viz_file = TASK2_PICTURES / 'eerie_visualization.png'
plt.savefig(viz_file, dpi=300, bbox_inches='tight')
print(f"  âœ“ å¯è§†åŒ–å·²ä¿å­˜: {viz_file}")

# æ‰“å°åˆ°å±å¹•
print("\n" + "="*70)
print("ğŸ“Š é¢„æµ‹ç»“æœé¢„è§ˆ")
print("="*70)
print(results_df.to_string(index=False))
print("="*70)

print("\nğŸ‰ ä»»åŠ¡2 å®Œæˆï¼")
print(f"   - CSV (ç»“æœ): {csv_file}")
print(f"   - TXT (æŠ¥å‘Š): {report_file}")
print(f"   - PNG (å›¾ç‰‡): {viz_file}")
print("="*70 + "\n")
